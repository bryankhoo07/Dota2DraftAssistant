{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "df1=pd.read_csv(\"picks_bans_2016.csv\")\n",
    "df2=pd.read_csv(\"picks_bans_2017.csv\")\n",
    "df3=pd.read_csv(\"picks_bans_2018.csv\")\n",
    "df4=pd.read_csv(\"picks_bans_2019.csv\")\n",
    "df5=pd.read_csv(\"picks_bans_2020.csv\")\n",
    "df6=pd.read_csv(\"picks_bans_2021.csv\")\n",
    "df7=pd.read_csv(\"picks_bans_2022.csv\")\n",
    "df8=pd.read_csv(\"picks_bans_2023.csv\")\n",
    "df9=pd.read_csv(\"picks_bans_2024.csv\")\n",
    "df10=pd.read_csv(\"picks_bans_2025Jan.csv\")\n",
    "df11=pd.read_csv(\"picks_bans_2025Feb.csv\")\n",
    "df12=pd.read_csv(\"picks_bans_2025Mar.csv\")\n",
    "df13=pd.read_csv(\"picks_bans_2025Apr.csv\")\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13], ignore_index=True)\n",
    "df14=pd.read_csv(\"dota2_hero_stats.csv\")\n",
    "\n",
    "\n",
    "\n",
    "combined_df.head()\n",
    "df14.head()"
   ],
   "id": "2f3b0217f2dd7c37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "picks_only_df = combined_df[combined_df['is_pick'] == True]\n",
    "\n",
    "\n",
    "hero_id_col_stats = 'id' if 'id' in df14.columns else 'id'\n",
    "hero_id_col_picks = 'hero_id'\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    picks_only_df,  # Use the filtered dataframe here\n",
    "    df14,\n",
    "    left_on=hero_id_col_picks,\n",
    "    right_on=hero_id_col_stats,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check if any picks didn't match with hero stats\n",
    "missing_matches = merged_df[merged_df[hero_id_col_stats].isna()].shape[0]\n",
    "print(f\"Records without matching hero stats: {missing_matches}\")\n",
    "\n",
    "# Save the combined dataset\n",
    "merged_df.to_csv('dota2_complete_dataset.csv', index=False)\n",
    "print(f\"Successfully merged data into 'dota2_final_dataset.csv'\")\n",
    "print(f\"Combined dataset has {merged_df.shape[0]} rows and {merged_df.shape[1]} columns\")"
   ],
   "id": "a606d432072b6472"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split # Make sure this is imported\n",
    "\n",
    "def prepare_hero_recommendation_data(df):\n",
    "    # List of all numeric hero stats to include\n",
    "    hero_stat_columns = [\n",
    "        'base_health', 'base_health_regen', 'base_mana', 'base_mana_regen',\n",
    "        'base_armor', 'base_mr', 'base_attack_min', 'base_attack_max',\n",
    "        'base_str', 'base_agi', 'base_int', 'str_gain', 'agi_gain', 'int_gain',\n",
    "        'attack_range', 'attack_rate', 'base_attack_time',\n",
    "        'attack_point', 'move_speed'\n",
    "    ]\n",
    "\n",
    "    # Convert stat columns to values\n",
    "    for col in hero_stat_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else:\n",
    "            print(f\"Warning: Stat column '{col}' not found in DataFrame.\")\n",
    "\n",
    "    # # Remove row if Nan values appear, trying to debug the NaN issue\n",
    "    df['hero_id'] = pd.to_numeric(df['hero_id'], errors='coerce')\n",
    "    df.dropna(subset=['hero_id'], inplace=True)\n",
    "    df['hero_id'] = df['hero_id'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    # Creating a dictionary when processing data, easier data access\n",
    "    hero_info = {}\n",
    "    unique_heroes_df = df.drop_duplicates('hero_id').set_index('hero_id')\n",
    "\n",
    "    for hero_id, row in unique_heroes_df.iterrows():\n",
    "        hero_data = {\n",
    "            'primary_attr': row.get('primary_attr', ''),\n",
    "            'roles': row.get('roles', '')\n",
    "        }\n",
    "        # Add all numeric stats, filling NaNs with 0.0\n",
    "        for stat in hero_stat_columns:\n",
    "            if stat in row:\n",
    "\n",
    "                stat_value = row[stat]\n",
    "                # Fill NaN with 0.0\n",
    "                hero_data[stat] = 0.0 if pd.isna(stat_value) else float(stat_value)\n",
    "            else:\n",
    "                 hero_data[stat] = 0.0 # Default if column doesn't exist\n",
    "\n",
    "        hero_info[hero_id] = hero_data\n",
    "\n",
    "\n",
    "    # Create attribute mapping\n",
    "    attr_to_idx = {'str': 0, 'agi': 1, 'int': 2, 'all': 3}\n",
    "\n",
    "    ## Extract roles\n",
    "    all_roles = set()\n",
    "    for hero_data in hero_info.values():\n",
    "        roles = hero_data.get('roles', '')\n",
    "        if isinstance(roles, str):\n",
    "            for role in roles.split(','):\n",
    "                clean_role = role.strip()\n",
    "                if clean_role:\n",
    "                    all_roles.add(clean_role)\n",
    "    role_to_idx = {role: idx for idx, role in enumerate(sorted(all_roles))}\n",
    "    num_roles = len(role_to_idx)\n",
    "    print(f\"Found {num_roles} unique roles\")\n",
    "    print(f\"Collected stats for {len(hero_info)} heroes\")\n",
    "\n",
    "\n",
    "    # Data containers\n",
    "    features_heroes = []\n",
    "    features_attrs = []\n",
    "    features_roles = []\n",
    "    features_stats = []\n",
    "    targets_next_heroes = []\n",
    "\n",
    "    # Process matches\n",
    "    print(f\"Processing {df['match_id'].nunique()} matches...\")\n",
    "    match_groups = df.groupby('match_id')\n",
    "\n",
    "    skipped_matches_count = 0\n",
    "    processed_matches_count = 0\n",
    "\n",
    "    for match_id, match_data in match_groups:\n",
    "        #appends the different team picks into 2 list\n",
    "        radiant_picks = match_data[match_data['team'] == 0]['hero_id'].tolist()\n",
    "        dire_picks = match_data[match_data['team'] == 1]['hero_id'].tolist()\n",
    "\n",
    "        # Skip matches with insufficient picks OR invalid hero IDs\n",
    "        if len(radiant_picks) < 4 or len(dire_picks) < 2:\n",
    "            skipped_matches_count += 1\n",
    "            continue\n",
    "\n",
    "        input_heroes = radiant_picks[:2] + dire_picks[:2]\n",
    "        target_hero = radiant_picks[3] # Target is the 4th Radiant hero\n",
    "\n",
    "        #Validate all heroes involved in this potential example\n",
    "        all_involved_heroes = input_heroes + [target_hero]\n",
    "        valid_match = True\n",
    "        for hero_id in all_involved_heroes:\n",
    "             # Check if hero_id is integer and exists in our processed hero_info\n",
    "            if not isinstance(hero_id, (int, np.integer)) or hero_id not in hero_info:\n",
    "                 #\n",
    "                 valid_match = False\n",
    "                 break\n",
    "        if not valid_match:\n",
    "            skipped_matches_count += 1\n",
    "            continue\n",
    "        #End Validation\n",
    "\n",
    "\n",
    "        # If validation passed, extract features\n",
    "        input_attrs = []\n",
    "        input_roles = []\n",
    "        input_stats_flat = []\n",
    "\n",
    "        for hero_id in input_heroes:\n",
    "\n",
    "            primary_attr = attr_to_idx.get(hero_info[hero_id]['primary_attr'], 0) # Default unknown attr\n",
    "\n",
    "            roles_str = str(hero_info[hero_id].get('roles', ''))\n",
    "            roles_list = roles_str.split(',') if roles_str else []\n",
    "            primary_role_str = roles_list[0].strip() if roles_list else ''\n",
    "            primary_role = role_to_idx.get(primary_role_str, num_roles) # Use num_roles as default index for unknown\n",
    "\n",
    "            hero_stats_list = []\n",
    "            for stat in hero_stat_columns:\n",
    "                stat_value = hero_info[hero_id].get(stat, 0.0)\n",
    "                hero_stats_list.append(float(stat_value))\n",
    "\n",
    "            input_attrs.append(primary_attr)\n",
    "            input_roles.append(primary_role)\n",
    "            input_stats_flat.extend(hero_stats_list)\n",
    "\n",
    "\n",
    "        # Final check on stats length before adding\n",
    "        expected_stat_len = len(hero_stat_columns) * 4\n",
    "        if len(input_stats_flat) != expected_stat_len:\n",
    "             print(f\"Warning: Final stat length mismatch for match {match_id}. Expected {expected_stat_len}, got {len(input_stats_flat)}. Skipping.\")\n",
    "             skipped_matches_count += 1\n",
    "             continue\n",
    "\n",
    "\n",
    "        # Add to datasets\n",
    "        features_heroes.append(input_heroes)\n",
    "        features_attrs.append(input_attrs)\n",
    "        features_roles.append(input_roles)\n",
    "        features_stats.append(input_stats_flat)\n",
    "        targets_next_heroes.append(target_hero)\n",
    "        processed_matches_count += 1\n",
    "\n",
    "\n",
    "    print(f\"Processed {processed_matches_count} examples.\")\n",
    "    print(f\"Skipped {skipped_matches_count} matches due to insufficient picks or invalid data.\")\n",
    "\n",
    "    if not features_heroes:\n",
    "         raise ValueError(\"No valid examples could be created. Check data quality and filtering logic.\")\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X_heroes = np.array(features_heroes)\n",
    "    X_attrs = np.array(features_attrs)\n",
    "    X_roles = np.array(features_roles)\n",
    "    X_stats = np.array(features_stats, dtype=np.float32) # Specify dtype here\n",
    "    y_heroes = np.array(targets_next_heroes)\n",
    "\n",
    "    # --- Add Explicit Check for NaNs/Infs in NumPy array ---\n",
    "    if np.isnan(X_stats).any():\n",
    "        print(\"ERROR: NaNs found in X_stats NumPy array BEFORE splitting!\")\n",
    "        # Optionally find where: np.where(np.isnan(X_stats))\n",
    "    if np.isinf(X_stats).any():\n",
    "        print(\"ERROR: Infs found in X_stats NumPy array BEFORE splitting!\")\n",
    "    # --- End Check ---\n",
    "\n",
    "\n",
    "    # Train-test split (ensure y_heroes has same length as X arrays)\n",
    "    if len(X_stats) != len(y_heroes):\n",
    "         raise ValueError(f\"Feature arrays ({len(X_stats)}) and target array ({len(y_heroes)}) have different lengths before split.\")\n",
    "\n",
    "    (X_train_heroes, X_test_heroes,\n",
    "     X_train_attrs, X_test_attrs,\n",
    "     X_train_roles, X_test_roles,\n",
    "     X_train_stats, X_test_stats,\n",
    "     y_train_heroes, y_test_heroes) = train_test_split(\n",
    "        X_heroes, X_attrs, X_roles, X_stats, y_heroes, # The arrays to split\n",
    "        test_size=0.2,                                 # Proportion for the test set\n",
    "        random_state=42                                # Ensures split is the same each time\n",
    "     ) # Correct closing parenthesis here\n",
    "    # Convert to tensors\n",
    "    X_train_heroes_tensor = torch.tensor(X_train_heroes, dtype=torch.long)\n",
    "    X_test_heroes_tensor = torch.tensor(X_test_heroes, dtype=torch.long)\n",
    "\n",
    "    X_train_attrs_tensor = torch.tensor(X_train_attrs, dtype=torch.long)\n",
    "    X_test_attrs_tensor = torch.tensor(X_test_attrs, dtype=torch.long)\n",
    "\n",
    "    X_train_roles_tensor = torch.tensor(X_train_roles, dtype=torch.long)\n",
    "    X_test_roles_tensor = torch.tensor(X_test_roles, dtype=torch.long)\n",
    "\n",
    "    # Stats are already float32 numpy arrays\n",
    "    X_train_stats_tensor = torch.from_numpy(X_train_stats)\n",
    "    X_test_stats_tensor = torch.from_numpy(X_test_stats)\n",
    "\n",
    "    y_train_heroes_tensor = torch.tensor(y_train_heroes, dtype=torch.long)\n",
    "    y_test_heroes_tensor = torch.tensor(y_test_heroes, dtype=torch.long)\n",
    "\n",
    "    if torch.isnan(X_train_stats_tensor).any():\n",
    "        print(\"ERROR: NaNs found in X_train_stats_tensor!\")\n",
    "\n",
    "    if torch.isnan(X_test_stats_tensor).any():\n",
    "        print(\"ERROR: NaNs found in X_test_stats_tensor!\")\n",
    "\n",
    "\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(\n",
    "        X_train_heroes_tensor, X_train_attrs_tensor, X_train_roles_tensor,\n",
    "        X_train_stats_tensor, y_train_heroes_tensor\n",
    "    )\n",
    "\n",
    "    test_dataset = TensorDataset(\n",
    "        X_test_heroes_tensor, X_test_attrs_tensor, X_test_roles_tensor,\n",
    "        X_test_stats_tensor, y_test_heroes_tensor\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    print(f\"Training set: {len(train_dataset)}, Test set: {len(test_dataset)}\")\n",
    "\n",
    "    # Determine num_heroes based on the MAX ID actually present + 1 (or use hero_info keys)\n",
    "    # max_hero_id_present = max(hero_info.keys()) if hero_info else 0\n",
    "    # num_heroes = max_hero_id_present + 1\n",
    "    # Safer: Use max ID from the original DataFrame after cleaning\n",
    "    max_hero_id_in_data = int(df['hero_id'].max())\n",
    "    num_heroes = max_hero_id_in_data + 1 # Make sure index 0 is handled if used (e.g., padding)\n",
    "    print(f\"Determined num_heroes for embedding: {num_heroes} (based on max hero_id {max_hero_id_in_data})\")\n",
    "\n",
    "    # Define default index for unknown roles\n",
    "    unknown_role_idx = num_roles # Assign the next available index\n",
    "    role_to_idx['<UNK_ROLE>'] = unknown_role_idx\n",
    "    num_roles += 1\n",
    "\n",
    "\n",
    "    # Return necessary information\n",
    "    return train_loader, test_loader, {\n",
    "        'num_heroes': num_heroes,\n",
    "        'num_attributes': len(attr_to_idx),\n",
    "        'num_roles': num_roles, # Updated count including UNK\n",
    "        'attr_mapping': attr_to_idx,\n",
    "        'role_mapping': role_to_idx, # Updated mapping\n",
    "        'hero_info': hero_info,\n",
    "        'stat_columns': hero_stat_columns,\n",
    "        'stat_dim': len(hero_stat_columns) * 4, # Total dimension of flattened hero stats (4 heroes)\n",
    "    }"
   ],
   "id": "bdc7a3fb73d52cca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the hero recommendation model with hero stats\n",
    "class HeroRecommender(nn.Module):\n",
    "    def __init__(self, num_heroes, num_roles, num_attributes, stat_dim=0,\n",
    "                 hero_embedding_dim=128, role_embedding_dim=32, attr_embedding_dim=16):\n",
    "        super(HeroRecommender, self).__init__()\n",
    "\n",
    "        # Hero embeddings\n",
    "        self.hero_embeddings = nn.Embedding(num_heroes, hero_embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Role embeddings\n",
    "        self.role_embeddings = nn.Embedding(num_roles, role_embedding_dim)\n",
    "\n",
    "        # Attribute embeddings\n",
    "        self.attr_embeddings = nn.Embedding(num_attributes, attr_embedding_dim)\n",
    "\n",
    "\n",
    "        # Stats processor (if stats are provided)\n",
    "        self.use_stats = stat_dim > 0\n",
    "\n",
    "        #Stat_dim=78, therefore 128 is sufficient\n",
    "        #Potentially changing the hidden layers in the future, if time permits\n",
    "        if self.use_stats:\n",
    "            self.stats_processor = nn.Sequential(\n",
    "                nn.Linear(stat_dim, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.4),\n",
    "\n",
    "                nn.Linear(128, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.4),\n",
    "\n",
    "                nn.Linear(256, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.4),\n",
    "\n",
    "                nn.Linear(512, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.4),\n",
    "\n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Dropout(0.4),\n",
    "            )\n",
    "            stats_output_dim = 128\n",
    "        else:\n",
    "            stats_output_dim = 0\n",
    "\n",
    "\n",
    "        # Total embedding dimension per hero\n",
    "        single_hero_dim = hero_embedding_dim + role_embedding_dim + attr_embedding_dim\n",
    "\n",
    "        # Total input dimension (4 heroes + processed stats if available)\n",
    "        total_input_dim = (single_hero_dim * 4) + stats_output_dim\n",
    "        print\n",
    "\n",
    "        # Hidden dimensions\n",
    "        hidden1 = total_input_dim*2\n",
    "        hidden2 = total_input_dim*4\n",
    "        hidden3 = total_input_dim*8\n",
    "        hidden4 = total_input_dim*16\n",
    "        hidden5 = total_input_dim*32\n",
    "\n",
    "        # Encoder network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(total_input_dim,hidden1),\n",
    "            nn.BatchNorm1d(hidden1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.BatchNorm1d(hidden2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "\n",
    "            nn.Linear(hidden2, hidden3),\n",
    "            nn.BatchNorm1d(hidden3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "\n",
    "            nn.Linear(hidden3, hidden4),\n",
    "            nn.BatchNorm1d(hidden4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "\n",
    "            nn.Linear(hidden4, hidden3),\n",
    "            nn.BatchNorm1d(hidden3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "\n",
    "            nn.Linear(hidden3, hidden2),\n",
    "            nn.BatchNorm1d(hidden2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "\n",
    "            nn.Linear(hidden2, hidden1),\n",
    "            nn.BatchNorm1d(hidden1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.55),\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.hero_decoder = nn.Linear(hidden1, num_heroes)\n",
    "\n",
    "    def forward(self, hero_ids, attr_ids, role_ids, hero_stats=None):\n",
    "        # Process each hero\n",
    "        hero_embeds = []\n",
    "\n",
    "        for i in range(4):  # Process 4 heroes\n",
    "            # Get hero embedding\n",
    "            hero_embed = self.hero_embeddings(hero_ids[:, i])\n",
    "\n",
    "\n",
    "            # Get attribute embedding\n",
    "            attr_embed = self.attr_embeddings(attr_ids[:, i])\n",
    "\n",
    "\n",
    "            # Get role embedding\n",
    "            role_embed = self.role_embeddings(role_ids[:, i])\n",
    "\n",
    "\n",
    "            # Combine embeddings for this hero\n",
    "            hero_combined = torch.cat([hero_embed, attr_embed, role_embed], dim=1)\n",
    "            hero_embeds.append(hero_combined)\n",
    "\n",
    "        #To process stats\n",
    "        if self.use_stats and hero_stats is not None:\n",
    "            processed_stats = self.stats_processor(hero_stats)\n",
    "            # Combine all hero embeddings and processed stats\n",
    "            combined_input = torch.cat(hero_embeds + [processed_stats], dim=1)\n",
    "\n",
    "        else:\n",
    "            # When stats are enabled but not provided, create zeros tensor\n",
    "            if self.use_stats:\n",
    "                batch_size = hero_ids.shape[0]\n",
    "                dummy_stats = torch.zeros(batch_size, 128, device=hero_ids.device)\n",
    "                combined_input = torch.cat(hero_embeds + [dummy_stats], dim=1)\n",
    "            else:\n",
    "                combined_input = torch.cat(hero_embeds, dim=1)\n",
    "\n",
    "        # Encode draft state\n",
    "        encoded = self.encoder(combined_input)\n",
    "\n",
    "        # Predict next hero\n",
    "        hero_scores = self.hero_decoder(encoded)\n",
    "\n",
    "        # Mask out already picked heroes\n",
    "        hero_mask = torch.zeros_like(hero_scores, dtype=torch.bool)\n",
    "        for i in range(hero_scores.size(0)):\n",
    "            for j in range(4):\n",
    "                hero_id = hero_ids[i, j].item()\n",
    "                if hero_id > 0:  # Skip padding\n",
    "                    hero_mask[i, hero_id] = True\n",
    "\n",
    "            # Also mask padding index\n",
    "            hero_mask[i, 0] = True\n",
    "\n",
    "        hero_scores = hero_scores.masked_fill(hero_mask, -100)\n",
    "\n",
    "\n",
    "        return hero_scores\n",
    "\n",
    "\n",
    "model = HeroRecommender(\n",
    "    num_heroes=feature_maps['num_heroes'],\n",
    "    num_roles=feature_maps['num_roles'],\n",
    "    num_attributes=feature_maps['num_attributes'],\n",
    "    stat_dim=stat_dim\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print( )"
   ],
   "id": "3f8be91d231ca328"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the training function\n",
    "def train_hero_recommender(model, train_loader, test_loader, num_epochs=20, lr=0.0001):\n",
    "    # Set device\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Metrics storage\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    train_top10_accs = []\n",
    "    test_top10_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_top1 = 0\n",
    "        correct_top10 = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            # Unpack the batch based on its structure\n",
    "            if len(batch) == 4:\n",
    "                hero_ids, attr_ids, role_ids, targets = batch\n",
    "                # Model doesn't use hero_stats, so don't need to pass it\n",
    "            elif len(batch) == 5:\n",
    "                hero_ids, attr_ids, role_ids, hero_stats, targets = batch\n",
    "                # ignore hero_stats to match model's forward signature\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Move to device\n",
    "            hero_ids = hero_ids.to(device)\n",
    "            attr_ids = attr_ids.to(device)\n",
    "            role_ids = role_ids.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            if len(targets.shape) > 1:\n",
    "                targets = targets.squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Forward pass - only using the parameters the model accept\n",
    "            optimizer.zero_grad()\n",
    "            if len(batch) == 4:\n",
    "                # Use the tensors that were already moved to device\n",
    "                hero_scores = model(hero_ids, attr_ids, role_ids)\n",
    "            elif len(batch) == 5:\n",
    "                # Move hero_stats to device and then use all tensors\n",
    "                hero_stats = hero_stats.to(device)\n",
    "                hero_scores = model(hero_ids, attr_ids, role_ids, hero_stats)\n",
    "            # Calculate loss\n",
    "            loss = criterion(hero_scores, targets)\n",
    "\n",
    "\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get top-1 and top-10 predictions\n",
    "            _, top1 = torch.max(hero_scores, 1)\n",
    "            _, top10 = torch.topk(hero_scores, k=10, dim=1)\n",
    "\n",
    "            # Convert tensors to numpy for easier comparison\n",
    "            top10_np = top10.cpu().numpy()\n",
    "            targets_np = targets.cpu().numpy()\n",
    "\n",
    "            # Count top-1 correct predictions\n",
    "            correct_top1 += (top1 == targets).sum().item()\n",
    "\n",
    "            # Count top-10 correct predictions\n",
    "            batch_size = targets.size(0)\n",
    "            for i in range(batch_size):\n",
    "                if targets_np[i] in top10_np[i]:\n",
    "                    correct_top10 += 1\n",
    "\n",
    "            total_samples += batch_size\n",
    "\n",
    "        # Test phase\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_correct_top1 = 0\n",
    "        test_correct_top10 = 0\n",
    "        test_total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                # Unpack the batch based on its structure\n",
    "                if len(batch) == 4:\n",
    "                    hero_ids, attr_ids, role_ids, targets = batch\n",
    "                    # Model doesn't use hero_stats, so we don't need to pass it\n",
    "                elif len(batch) == 5:\n",
    "                    hero_ids, attr_ids, role_ids, hero_stats, targets = batch\n",
    "                    # We'll ignore hero_stats to match model's forward signature\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                # Move to device\n",
    "                hero_ids = hero_ids.to(device)\n",
    "                attr_ids = attr_ids.to(device)\n",
    "                role_ids = role_ids.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                if len(targets.shape) > 1:\n",
    "                    targets = targets.squeeze()\n",
    "\n",
    "\n",
    "                # Forward pass - only using the parameters the model accepts\n",
    "                hero_scores = model(hero_ids, attr_ids, role_ids)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(hero_scores, targets)\n",
    "\n",
    "                # Skip NaN loss\n",
    "                if torch.isnan(loss):\n",
    "                    continue\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Get top-1 and top-10 predictions\n",
    "                _, top1 = torch.max(hero_scores, 1)\n",
    "                _, top10 = torch.topk(hero_scores, k=10, dim=1)\n",
    "\n",
    "                # Convert tensors to numpy for easier comparison\n",
    "                top10_np = top10.cpu().numpy()\n",
    "                targets_np = targets.cpu().numpy()\n",
    "\n",
    "                # Count top-1 correct predictions\n",
    "                test_correct_top1 += (top1 == targets).sum().item()\n",
    "\n",
    "                # Count top-10 correct predictions\n",
    "                batch_size = targets.size(0)\n",
    "                for i in range(batch_size):\n",
    "                    if targets_np[i] in top10_np[i]:\n",
    "                        test_correct_top10 += 1\n",
    "\n",
    "                test_total_samples += batch_size\n",
    "\n",
    "        # Calculate metrics\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc_top1 = correct_top1 / total_samples if total_samples > 0 else 0\n",
    "        train_acc_top10 = correct_top10 / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        test_loss = test_loss / len(test_loader)\n",
    "        test_acc_top1 = test_correct_top1 / test_total_samples if test_total_samples > 0 else 0\n",
    "        test_acc_top10 = test_correct_top10 / test_total_samples if test_total_samples > 0 else 0\n",
    "\n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accs.append(train_acc_top1)\n",
    "        test_accs.append(test_acc_top1)\n",
    "        train_top10_accs.append(train_acc_top10)\n",
    "        test_top10_accs.append(test_acc_top10)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Top-1 Acc: {train_acc_top1:.4f}, Top-10 Acc: {train_acc_top10:.4f}\")\n",
    "        print(f\"Validation Loss: {test_loss:.4f}, Top-1 Acc: {test_acc_top1:.4f}, Top-10 Acc: {test_acc_top10:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "    return model, train_losses, test_losses, train_accs, test_accs, train_top10_accs, test_top10_accs"
   ],
   "id": "75f8abe42d70545b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_epochs = 50  # Adjust as needed\n",
    "model, train_losses, test_losses, train_accs, test_accs, train_top10_accs, test_top10_accs = train_hero_recommender(\n",
    "    model, train_loader, test_loader, num_epochs=num_epochs\n",
    ")"
   ],
   "id": "70b73dd7de8d2ba7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize training progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot losses\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "\n",
    "# Plot top-1 accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accs, label='Train Top-1 Acc')\n",
    "plt.plot(test_accs, label='Test Top-1 Acc')\n",
    "plt.title('Top-1 Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot top-10 accuracy\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(train_top10_accs, label='Train Top-10 Acc')\n",
    "plt.plot(test_top10_accs, label='Test Top-10 Acc')\n",
    "plt.title('Top-10 Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics.png')\n",
    "plt.show()"
   ],
   "id": "385d0b79968be8ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "example_input = (\n",
    "    torch.tensor([[1, 2, 3, 4]], dtype=torch.long),  # Example hero IDs\n",
    "    torch.tensor([[0, 1, 2, 0]], dtype=torch.long),  # Example attribute IDs\n",
    "    torch.tensor([[5, 3, 1, 2]], dtype=torch.long),  # Example role IDs\n",
    "    torch.randn(1, 76)  # Example hero stats\n",
    ")\n",
    "\n",
    "model_save_path = '/content/drive/MyDrive/hero_recommender_model5th.pth'\n",
    "torch.save(model.state_dict(), model_save_path)  # Save model state dict to a file\n"
   ],
   "id": "41ec5d2c379fe873"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "84affa57646add3c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
